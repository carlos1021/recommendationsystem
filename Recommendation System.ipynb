{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "070b6215-6aec-4b50-8595-8df1f6c19c16",
   "metadata": {},
   "source": [
    "# Demo 1: Designing a Basic Recommendation System\n",
    "\n",
    "## Wednesday 6/21/2023\n",
    "\n",
    "### Kyle He, Carlos Gonzalez\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hi hello how are you\n",
    "\n",
    "\n",
    "i am good how was your day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7701c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7989b3cc-641b-4c92-9cdb-d1e3f7bad88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79c180d5-400b-4145-9c6b-108d34f3b84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization\n",
    "tokenize = nltk.word_tokenize(sentence)\n",
    "tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019b9e33-9d03-4be1-8222-a461e434ce28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "what definition do you want to look up? meditation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['continuous and profound contemplation or musing on a subject or series of subjects of a deep or abstruse nature',\n",
       " '(religion) contemplation of spiritual matters (usually on religious or philosophical subjects)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display all the definitions of a word into a list\n",
    "x = input(\"what definition do you want to look up?\")\n",
    "meditation_synsets = wn.synsets(x)\n",
    "all_def_meditation = [0]*len(meditation_synsets)\n",
    "for i in range(len(meditation_synsets)):\n",
    "    all_def_meditation[i] = meditation_synsets[i].definition()\n",
    "all_def_meditation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b56eb4e-5b88-40c0-9c0f-d4dd1dfcd4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What word do you want to look up synonyms for? great\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms for 'great':\n",
      "swell\n",
      "cracking\n",
      "not_bad\n",
      "majuscule\n",
      "large\n",
      "slap-up\n",
      "neat\n",
      "smashing\n",
      "heavy\n",
      "corking\n",
      "capital\n",
      "groovy\n",
      "big\n",
      "nifty\n",
      "dandy\n",
      "keen\n",
      "peachy\n",
      "bully\n",
      "bang-up\n",
      "expectant\n",
      "with_child\n",
      "enceinte\n",
      "gravid\n",
      "outstanding\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Goal: Design a basic recommendation system using the wordnet library\n",
    "'''\n",
    "\n",
    "#Helper function\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for synsets in wn.synsets(word):\n",
    "        for lemma in synsets.lemmas():\n",
    "            #add ALL synonyms to list\n",
    "            \n",
    "            synonyms.append(lemma.name())\n",
    "    #remove duplicate entries in our synonyms list\n",
    "    synonyms = list(set(synonyms))\n",
    "    try:\n",
    "        synonyms.remove(word)\n",
    "    except:\n",
    "        print(\"\")\n",
    "    return synonyms\n",
    "\n",
    "# def get_synonyms(word):\n",
    "#     synonyms = []\n",
    "#     word_synsets = wn.synsets(word)\n",
    "#     for synset in word_synsets:\n",
    "#         for lemma in synset.lemmas():\n",
    "#             synonym = lemma.name()\n",
    "#             if synonym != word:\n",
    "#                 synonym_synsets = wn.synsets(synonym)\n",
    "#                 if synonym_synsets:\n",
    "#                     similarity_score = synset.path_similarity(synonym_synsets[0])\n",
    "#                     if similarity_score is not None:\n",
    "#                         synonyms.append((synonym, similarity_score))\n",
    "    \n",
    "#     synonyms = list(set(synonyms))\n",
    "#     try:\n",
    "#         synonyms.remove((word, None))\n",
    "#     except:\n",
    "#         print(\"\")\n",
    "\n",
    "#     return synonyms\n",
    "\n",
    "# def get_synonyms(word):\n",
    "#     synonyms = []\n",
    "#     word_synsets = wn.synsets(word)\n",
    "#     for synset in word_synsets:\n",
    "#         synonyms.extend((lemma.name(), synset.path_similarity(wn.synset(lemma.synset().name()))) \n",
    "#                         for lemma in synset.lemmas() if lemma.name() != word)\n",
    "    \n",
    "#     return list(set(synonyms))\n",
    "\n",
    "\n",
    "# Helper function\n",
    "# def get_synonyms(word):\n",
    "#     synonyms = []\n",
    "#     for synset in wn.synsets(word):\n",
    "#         for lemma in synset.lemmas():\n",
    "#             synonym = lemma.name()\n",
    "#             similarity_score = synset.wup_similarity(wn.synsets(word)[0])\n",
    "#             synonyms.append((synonym, similarity_score))\n",
    "#     synonyms = list(set(synonyms))\n",
    "#     try:\n",
    "#         synonyms.remove(word)\n",
    "#     except:\n",
    "#         print(\"\")\n",
    "#     return synonyms\n",
    "\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "# def get_synonyms(word):\n",
    "#     synonyms = []\n",
    "#     word_synsets = wn.synsets(word)\n",
    "#     for synset in word_synsets:\n",
    "#         for lemma in synset.lemmas():\n",
    "#             synonym = lemma.name()\n",
    "#             if synonym != word:\n",
    "#                 synonym_synsets = wn.synsets(synonym)\n",
    "#                 if synonym_synsets:\n",
    "#                     similarity_scores = [synset.path_similarity(syn) for syn in synonym_synsets]\n",
    "#                     valid_scores = [score for score in similarity_scores if score is not None]\n",
    "#                     if valid_scores:\n",
    "#                         max_score = max(valid_scores)\n",
    "#                         synonyms.append((synonym, max_score))\n",
    "\n",
    "#     synonyms = list(set(synonyms))\n",
    "#     try:\n",
    "#         synonyms.remove((word, None))\n",
    "#     except:\n",
    "#         print(\"\")\n",
    "\n",
    "#     return synonyms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#design the synonym_recommendation function, which will \n",
    "#recommend a synonym for the user\n",
    "def recommend_synonym(word):\n",
    "    synonyms = get_synonyms(word)\n",
    "    if len(synonyms) > 0:\n",
    "        print(f\"Synonyms for '{word}':\")\n",
    "        for synonym in synonyms:\n",
    "            print(synonym)\n",
    "    else:\n",
    "        print(f\"No synonyms found for '{word}'.\")\n",
    "\n",
    "user_input = input(\"What word do you want to look up synonyms for?\")\n",
    "#wn.synsets(user_input)\n",
    "recommend_synonym(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e29e93-863a-425a-b169-53cb4559ed02",
   "metadata": {},
   "source": [
    "# Part 2: Optimization\n",
    "\n",
    "## Assigning a similarity score for each given synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "077d2f9f-1f43-4017-9eff-437e2da299b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words 'great' and 'capital' are '0.2' percent similar!\n"
     ]
    }
   ],
   "source": [
    "#Testing Wu-Palmer Similarity Test\n",
    "great_1 = wn.synsets(\"great\")[0]\n",
    "great_2 = wn.synsets(\"great\")[5]\n",
    "\n",
    "similarity_score = great_1.wup_similarity(great_2)\n",
    "print(f\"The words '{great_1.lemma_names()[0]}' and '{great_2.lemma_names()[0]}' are '{similarity_score}' percent similar!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f3bdc-9fb7-4341-a527-aea7080e691f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
